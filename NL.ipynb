{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d042b2b-da31-4d15-8c0d-4ca3efd1e5e1",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b792ff-456b-4a2f-a87f-187b2c50b11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5d023e-c368-4473-b72e-a340285586be",
   "metadata": {},
   "source": [
    "## Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cc51046-048b-48ca-b03e-813d25158f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(os.path.join(os.getcwd(), 'gisette.pickle'), compression='infer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb48c10e-81e9-4655-bc7f-ea8d8b182be3",
   "metadata": {},
   "source": [
    "## Summary of the Loaded Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee014c2b-e544-4c22-ba11-3f39b14c12a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['training', 'validation', 'testing'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8785fbb-d6cf-4bd8-947b-bb00ddd13437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['data', 'labels'])\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(type(df['training']))\n",
    "print(df['training'].keys())\n",
    "print(df['training']['labels'][44])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7417488-5f06-4e3b-a00a-453b57eddcb7",
   "metadata": {},
   "source": [
    "## Train, Test and Validation split\n",
    "#### Since the test data doesnot have labels, so training data is split into 5k and 1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e947252-36f2-4f25-bed8-e22ba30cece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_x = df['training']['data']\n",
    "dataset_train_y = df['training']['labels']\n",
    "\n",
    "dataset_validation_x = df['validation']['data']\n",
    "dataset_validation_y = df['validation']['labels']\n",
    "\n",
    "dataset_test_x = df['training']['data'][5000:]\n",
    "dataset_test_y = df['training']['labels'][5000:]\n",
    "\n",
    "dataset_train_x = df['training']['data'][:5000]\n",
    "dataset_train_y = df['training']['labels'][:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1162dd82-d314-448c-9be5-c2255eae6546",
   "metadata": {},
   "source": [
    "## Summary of Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "698dc971-7c70-466b-a033-8ff7cc4aaf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training   :  (5000, 5000) (5000,)\n",
      "validation :  (1000, 5000) (1000,)\n",
      "Testing    :  (1000, 5000) (1000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training   : \", dataset_train_x.shape, dataset_train_y.shape)\n",
    "print(\"validation : \", dataset_validation_x.shape, dataset_validation_y.shape)\n",
    "print(\"Testing    : \", dataset_test_x.shape, dataset_test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d275b0-9b0b-4f77-9b5c-34515141c564",
   "metadata": {},
   "source": [
    "## Pre-Processing the Values\n",
    "#### Changing labels to {0,1} and the attributes value to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d29f8037-1c84-4012-a7f1-fb529f690dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1. -1.  1.]\n",
      "tarin [1 0 1 1 1]\n",
      "val [1 1 0 1 1]\n",
      "test [1 1 1 0 1]\n",
      "tarin [0.55  0.    0.495 ... 0.    0.    0.983]\n",
      "val [0.688 0.    0.    ... 0.    0.769 0.   ]\n",
      "test [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "dataset_train_x = dataset_train_x/1000\n",
    "dataset_validation_x = dataset_validation_x/1000\n",
    "dataset_test_x = dataset_test_x/1000\n",
    "\n",
    "def change_label(lt):\n",
    "    res = []\n",
    "    for x in lt:\n",
    "        if x == -1:\n",
    "            res.append(0)\n",
    "        else :\n",
    "            res.append(1)\n",
    "    return res\n",
    "\n",
    "print(dataset_test_y[0:5])\n",
    "dataset_train_y = np.array(change_label(dataset_train_y))\n",
    "dataset_validation_y = np.array(change_label(dataset_validation_y))\n",
    "dataset_test_y = np.array(change_label(dataset_test_y))\n",
    "print(\"tarin\",dataset_train_y[0:5])\n",
    "print(\"val\",dataset_validation_y[0:5])\n",
    "print(\"test\",dataset_test_y[0:5])\n",
    "\n",
    "print(\"tarin\",dataset_train_x[0])\n",
    "print(\"val\",dataset_validation_x[0])\n",
    "print(\"test\",dataset_test_x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90125150-2bdf-4099-840b-4e2c48be6c53",
   "metadata": {},
   "source": [
    "## Analyzing the Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12788db4-23ee-44f6-8bf5-03ff44c7904e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX : 0.999\n",
      "MIN : 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"MAX :\", max(dataset_train_x[0][:]))\n",
    "print(\"MIN :\", min(dataset_train_x[0][:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27dbf33-bfe1-4de9-bf9d-82d812f00eab",
   "metadata": {},
   "source": [
    "## Callback to visualize the training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b35f898d-aed1-4678-9dd2-01667974f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class real_time_callback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss_list = []\n",
    "        self.val_loss = []\n",
    "        self.acc_list = []\n",
    "        self.val_acc = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "      self.loss_list.append(logs.get('loss'))\n",
    "      self.val_loss.append(logs.get('val_loss'))\n",
    "      self.acc_list.append(logs.get('binary_accuracy'))\n",
    "      #self.acc_list.append(logs.get('accuracy'))\n",
    "      self.val_acc.append(logs.get('val_binary_accuracy'))\n",
    "      #self.val_acc.append(logs.get('val_accuracy'))\n",
    "\n",
    "      fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20,4))\n",
    "\n",
    "      ax1.plot(self.loss_list)\n",
    "      ax1.set_title('model loss')\n",
    "      ax1.set_ylabel('loss')\n",
    "      ax1.set_xlabel('epoch')\n",
    "      ax1.legend(['train', 'val'], loc='upper left')\n",
    "      ax1.plot(self.val_loss)\n",
    "\n",
    "      ax2.set_title('model accuracy')\n",
    "      ax2.set_ylabel('accuracy')\n",
    "      ax2.set_xlabel('epoch')\n",
    "      ax2.legend(['train', 'val'], loc='upper left')\n",
    "      ax2.plot(self.acc_list)\n",
    "      ax2.plot(self.val_acc)\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79af08a-952f-4d03-b979-28d56efc314e",
   "metadata": {},
   "source": [
    "## Perfroming Search and Training model to find Optimal Capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0362b3b-c560-4c62-8e68-44f3f6e644a5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_1 = 0\n",
    "filter_2 = 0\n",
    "\n",
    "EPOCH = 1000\n",
    "\n",
    "flters = [[2,0] , [4,0], [8,0], [16,0], [32,0],\n",
    "          [2,2] , [4,2], [8,2], [16,2], [32,2],\n",
    "          [2,4] , [4,4], [8,4], [16,4], [32,4],\n",
    "          [2,8] , [4,8], [8,8], [16,8], [32,8],\n",
    "          [2,16] , [4,16], [8,16], [16,16], [32,16],\n",
    "          [2,23] , [4,32], [8,32], [16,32], [32,32]\n",
    "]\n",
    "\n",
    "for c,i in enumerate(flters):\n",
    "    filter_1 = i[0]\n",
    "    filter_2 = i[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(filter_1, input_dim=dataset_train_x.shape[1], activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    if filter_2 > 0:\n",
    "        model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    #model.summary()\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.000001), loss=keras.losses.BinaryCrossentropy(), metrics=['binary_accuracy'])\n",
    "\n",
    "    history = model.fit(dataset_train_x, dataset_train_y, validation_data=(dataset_validation_x, dataset_validation_y), epochs=EPOCH, batch_size=32, callbacks=[real_time_callback()])\n",
    "    \n",
    "    file_name = 'model_' + str(filter_1) + '_' + str(filter_2) + '_' + str(EPOCH)\n",
    "    model.save('model/' + file_name)\n",
    "    with open('history/' + file_name, 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f72dca-a7dd-43fd-8074-bdddcbac761b",
   "metadata": {},
   "source": [
    "## Read History of the Trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ec1b8e-333d-487f-91cb-8422f8549d89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('history/model_32_32_1000', \"rb\") as file_pi:\n",
    "    hist = pickle.load(file_pi)\n",
    "    print(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8dde36-cd7b-4887-b63e-0a1c12b9eea9",
   "metadata": {},
   "source": [
    "## Manual Prediction of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f41738b9-6c22-4cd7-868e-eaa82f3e90e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "[[0.98584807]\n",
      " [0.01081104]\n",
      " [0.99679893]\n",
      " [0.9471442 ]\n",
      " [0.98803836]] [1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(dataset_train_x[:5]), dataset_train_y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39effdb-43f7-4244-a83f-689e3f5b5166",
   "metadata": {},
   "source": [
    "## Loading the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8741fb8e-4f8e-40f8-a922-31731945f975",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 544us/step - loss: 0.0675 - binary_accuracy: 0.9800\n",
      "[0.06745307892560959, 0.9800000190734863]\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 1000\n",
    "filter_1 = 16\n",
    "filter_2 = 0\n",
    "file_name = 'model_' + str(filter_1) + '_' + str(filter_2) + '_' + str(EPOCH)\n",
    "loaded_model = keras.models.load_model('model/' + file_name)\n",
    "\n",
    "dataset_x = dataset_test_x \n",
    "dataset_y = dataset_test_y\n",
    "count = len(dataset_test_y)\n",
    "\n",
    "print(loaded_model.evaluate(dataset_x[:count], dataset_y[:count]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15d374d5-4160-4fa3-aaf6-c553db2c17e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 16)                80016     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,097\n",
      "Trainable params: 80,065\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae23799c-6944-4203-8541-5c7a5114240d",
   "metadata": {},
   "source": [
    "## Draw Model Layer Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2dbed54e-fa9f-4822-a6bc-f8bfc11dd5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import visualkeras\n",
    "visualkeras.layered_view(loaded_model, legend=True, to_file='output_model.png').show()"
   ]
  }
 ],
 "metadata": {
  "autoscrollcelloutput": true,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
